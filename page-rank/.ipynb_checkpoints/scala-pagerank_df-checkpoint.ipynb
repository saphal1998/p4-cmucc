{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce06e679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, StructField, StringType}\n",
       "import org.apache.spark.sql.functions.{col, lit}\n",
       "import org.apache.spark.sql._\n",
       "import spark.implicits._\n",
       "import org.apache.spark.broadcast.Broadcast\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, StringType}\n",
    "import org.apache.spark.sql.functions.{col, lit}\n",
    "import org.apache.spark.sql._\n",
    "import spark.implicits._\n",
    "import org.apache.spark.broadcast.Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47b59c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data: ()org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n",
       "graphDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [follower: string, followee: string]\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data() = {\n",
    "    val graph = Seq(Row(\"0\",\"2\"),Row(\"1\",\"0\"),Row(\"1\",\"2\"),Row(\"1\",\"3\"), Row(\"2\", \"3\"))\n",
    "    val graphDF = spark.createDataFrame(\n",
    "        sc.parallelize(graph), \n",
    "        StructType(\n",
    "            List(\n",
    "                StructField(\"follower\", StringType), \n",
    "                StructField(\"followee\", StringType)\n",
    "            )\n",
    "        )\n",
    "    ).as(\"social_graph\")\n",
    "    graphDF.cache()\n",
    "    \n",
    "    graphDF\n",
    "}\n",
    "\n",
    "val graphDF = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad17a50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_users: (graphDF: org.apache.spark.sql.DataFrame)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n",
       "users: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [user_id: string]\n",
       "user_count: org.apache.spark.broadcast.Broadcast[Long] = Broadcast(234)\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_users(graphDF: DataFrame) = {\n",
    "    graphDF.select(col(\"followee\"))\n",
    "        .union(graphDF.select(col(\"follower\")))\n",
    "        .withColumnRenamed(\"followee\",\"user_id\").distinct.as(\"users\")\n",
    "}\n",
    "\n",
    "\n",
    "val users = get_users(graphDF)\n",
    "val user_count = sc.broadcast(users.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f3c3dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize_ranks: (users: org.apache.spark.sql.DataFrame)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n",
       "rank: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [user_id: string, rank_value: double]\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_ranks(users: DataFrame) = {\n",
    "    users.select(col(\"user_id\"), lit(1.0/user_count.value).as(\"rank_value\")).as(\"rank\")\n",
    "}\n",
    "\n",
    "val rank = initialize_ranks(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62438262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_followers_per_user: (social_graph: org.apache.spark.sql.DataFrame)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n",
       "followers: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [followee: string, followers: array<string>]\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_followers_per_user(social_graph: DataFrame) = {\n",
    "    social_graph.groupBy(\"followee\").agg(collect_list(\"follower\").as(\"followers\")).as(\"followers\")\n",
    "}\n",
    "\n",
    "val followers = get_followers_per_user(graphDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5057a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_following_per_user: (social_graph: org.apache.spark.sql.DataFrame)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n",
       "following: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [follower: string, following: array<string>]\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_following_per_user(social_graph: DataFrame) = {\n",
    "    social_graph.groupBy(\"follower\").agg(collect_list(\"followee\").as(\"following\")).as(\"following\")\n",
    "}\n",
    "val following = get_following_per_user(graphDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "350f9de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+---------+\n",
      "|user_id|rank_value|followers|following|\n",
      "+-------+----------+---------+---------+\n",
      "|      2|      0.25|   [0, 1]|      [3]|\n",
      "|      0|      0.25|      [1]|      [2]|\n",
      "|      3|      0.25|   [1, 2]|     null|\n",
      "|      1|      0.25|     null|[0, 2, 3]|\n",
      "+-------+----------+---------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "enhanced_rank: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [user_id: string, rank_value: double ... 2 more fields]\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var enhanced_rank = rank\n",
    "    .join(followers, col(\"followers.followee\") === col(\"rank.user_id\"), \"left\")\n",
    "    .select(col(\"user_id\").as(\"user_id\"), col(\"rank_value\"), col(\"followers\")).as(\"rank_followers\")\n",
    "    .join(following, col(\"following.follower\") === col(\"rank_followers.user_id\"), \"left\")\n",
    "    .select(col(\"user_id\"), col(\"rank_value\"), col(\"followers\"), col(\"following\")).as(\"rank_followers_following\")\n",
    "    .as(\"rank\")\n",
    "enhanced_rank.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "270dc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "// val non_dangling_users = following_followers_with_rank.filter(col(\"following\").isNotNull)\n",
    "// val dangling_users = following_followers_with_rank.filter(col(\"following\").isNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1dfe4f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+---------+-------------------+\n",
      "|user_id|rank_value|followers|following|      contributions|\n",
      "+-------+----------+---------+---------+-------------------+\n",
      "|      2|      0.25|   [0, 1]|      [3]|               0.25|\n",
      "|      0|      0.25|      [1]|      [2]|               0.25|\n",
      "|      3|      0.25|   [1, 2]|     null|               0.25|\n",
      "|      1|      0.25|     null|[0, 2, 3]|0.08333333333333333|\n",
      "+-------+----------+---------+---------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "get_contributions: (rank: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n",
       "contributions: org.apache.spark.sql.DataFrame = [user_id: string, rank_value: double ... 3 more fields]\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_contributions(rank: DataFrame) = {\n",
    "    rank.withColumn(\"contributions\", col(\"rank_value\") / when(col(\"following\").isNotNull, size(col(\"following\"))).otherwise(1))\n",
    "}\n",
    "\n",
    "val contributions = get_contributions(enhanced_rank)\n",
    "contributions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24331b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|contribute_to|      contributions|\n",
      "+-------------+-------------------+\n",
      "|            3| 0.3333333333333333|\n",
      "|            0|0.08333333333333333|\n",
      "|         null|               0.25|\n",
      "|            2| 0.3333333333333333|\n",
      "+-------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "explode_and_sum_contributions: (contributions: org.apache.spark.sql.DataFrame)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n",
       "summed_contributions: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [contribute_to: string, contributions: double]\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def explode_and_sum_contributions(contributions: DataFrame) = {\n",
    "    val exploded_contribution = contributions.select(col(\"user_id\"),col(\"rank_value\"), col(\"followers\"), explode_outer(col(\"following\")).as(\"contribute_to\"), col(\"contributions\")).as(\"exploded_contributions\")\n",
    "    exploded_contribution.groupBy(\"contribute_to\").agg(sum(\"contributions\").alias(\"contributions\")).as(\"summed_contributions\")\n",
    "}\n",
    "\n",
    "val summed_contributions = explode_and_sum_contributions(contributions)\n",
    "// val total_dangling_bonus = summed_contributions.select(\"contributions\").where(col(\"contribute_to\").isNull).first.getDouble(0)\n",
    "summed_contributions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a37c5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------------------+---------+\n",
      "|user_id|followers|         rank_value|following|\n",
      "+-------+---------+-------------------+---------+\n",
      "|      2|   [0, 1]| 0.3739583333333333|      [3]|\n",
      "|      0|      [1]|0.16145833333333331|      [2]|\n",
      "|      3|   [1, 2]| 0.3739583333333333|     null|\n",
      "|      1|     null|           0.090625|[0, 2, 3]|\n",
      "+-------+---------+-------------------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "calculate_rank: (contributions: org.apache.spark.sql.DataFrame, summed_contributions: org.apache.spark.sql.DataFrame, user_count: org.apache.spark.broadcast.Broadcast[Long])org.apache.spark.sql.DataFrame\n",
       "new_ranks: org.apache.spark.sql.DataFrame = [user_id: string, followers: array<string> ... 2 more fields]\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_rank(contributions: DataFrame, summed_contributions: DataFrame, user_count: Broadcast[Long]) = {\n",
    "\n",
    "    val new_ranks_without_dangling = contributions\n",
    "        .drop(\"contributions\").join(summed_contributions, col(\"contribute_to\") === col(\"user_id\"), \"left\")\n",
    "        .withColumn(\"contributions\", when(col(\"contributions\").isNotNull, col(\"contributions\")).otherwise(lit(0)))\n",
    "        .select(col(\"user_id\"), col(\"followers\"), col(\"rank_value\"), col(\"following\"), col(\"contributions\").as(\"rank_contributions\"))\n",
    "        .crossJoin(summed_contributions.filter(col(\"contribute_to\").isNull).select(col(\"contributions\").as(\"remainder\")))\n",
    "        .withColumn(\"rank_value\", (col(\"remainder\")/ user_count.value) + col(\"rank_contributions\"))\n",
    "        .drop(\"rank_contributions\", \"remainder\")\n",
    "    new_ranks_without_dangling.withColumn(\"rank_value\", (col(\"rank_value\") * 0.85) + (0.15 / user_count.value))\n",
    "}\n",
    "\n",
    "// def calculate_rank(contributions: DataFrame, summed_contributions: DataFrame) = {\n",
    "//     val remainder = summed_contributions.agg(sum(\"contributions\").as(\"remainder\")).withColumn(\"remainder\", (lit(1) - col(\"remainder\"))/user_count.value)\n",
    "//     val new_ranks = contributions\n",
    "//         .crossJoin(remainder)\n",
    "//         .drop(\"contributions\")\n",
    "//         .join(summed_contributions, col(\"contribute_to\") === col(\"user_id\"), \"left\").drop(\"contribute_to\")\n",
    "//         .select(col(\"user_id\"), col(\"followers\"), col(\"rank_value\"), col(\"following\"), col(\"contributions\").as(\"rank_contributions\"), col(\"remainder\"))\n",
    "//         .withColumn(\"final_rank\", (when(col(\"rank_contributions\").isNotNull, col(\"rank_contributions\")).otherwise(lit(0)) + col(\"remainder\")))\n",
    "//         .withColumn(\"rank_value\", (col(\"final_rank\") * 0.85) + (0.15 / user_count.value))\n",
    "//         .select(col(\"user_id\"), col(\"followers\"), col(\"following\"), col(\"rank_value\"))\n",
    "//     new_ranks\n",
    "// }\n",
    "val new_ranks = calculate_rank(contributions, summed_contributions, user_count)\n",
    "new_ranks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6dab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------------------+---------+\n",
      "|user_id|followers|         rank_value|following|\n",
      "+-------+---------+-------------------+---------+\n",
      "|      2|   [0, 1]| 0.3739583333333333|      [3]|\n",
      "|      0|      [1]|0.16145833333333331|      [2]|\n",
      "|      3|   [1, 2]| 0.3739583333333333|     null|\n",
      "|      1|     null|           0.090625|[0, 2, 3]|\n",
      "+-------+---------+-------------------+---------+\n",
      "\n",
      "()+-------+---------+-------------------+---------+\n",
      "|user_id|followers|         rank_value|following|\n",
      "+-------+---------+-------------------+---------+\n",
      "|      2|   [0, 1]|0.27988281249999997|      [3]|\n",
      "|      0|      [1]|0.14264322916666666|      [2]|\n",
      "|      3|   [1, 2]| 0.4605078124999999|     null|\n",
      "|      1|     null|0.11696614583333331|[0, 2, 3]|\n",
      "+-------+---------+-------------------+---------+\n",
      "\n",
      "()+-------+---------+-------------------+---------+\n",
      "|user_id|followers|         rank_value|following|\n",
      "+-------+---------+-------------------+---------+\n",
      "|      2|   [0, 1]| 0.2897450629340277|      [3]|\n",
      "|      0|      [1]|0.16849831814236108|      [2]|\n",
      "|      3|   [1, 2]|  0.406398708767361|     null|\n",
      "|      1|     null|0.13535791015624998|[0, 2, 3]|\n",
      "+-------+---------+-------------------+---------+\n",
      "\n",
      "()23/03/26 00:57:27 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:30 ERROR TorrentBroadcast: Store broadcast broadcast_1167 fail, remove all pieces of the broadcast\n",
      "23/03/26 00:57:30 ERROR TorrentBroadcast: Store broadcast broadcast_1172 fail, remove all pieces of the broadcast\n",
      "23/03/26 00:57:30 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:32 ERROR TorrentBroadcast: Store broadcast broadcast_1177 fail, remove all pieces of the broadcast\n",
      "23/03/26 00:57:33 ERROR TorrentBroadcast: Store broadcast broadcast_1178 fail, remove all pieces of the broadcast\n",
      "23/03/26 00:57:33 ERROR TorrentBroadcast: Store broadcast broadcast_1179 fail, remove all pieces of the broadcast\n",
      "23/03/26 00:57:28 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:28 ERROR TorrentBroadcast: Store broadcast broadcast_1173 fail, remove all pieces of the broadcast\n",
      "23/03/26 00:57:35 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:36 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:37 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:39 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:40 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:41 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n",
      "23/03/26 00:57:42 WARN TaskMemoryManager: Failed to allocate a page (2097136 bytes), try again.\n"
     ]
    }
   ],
   "source": [
    "var number_of_iterations = 10\n",
    "\n",
    "while(number_of_iterations > 0) {\n",
    "    val contributions = get_contributions(enhanced_rank)\n",
    "    val summed_contributions = explode_and_sum_contributions(contributions)\n",
    "    val new_ranks = calculate_rank(contributions, summed_contributions, user_count)\n",
    "    enhanced_rank = new_ranks\n",
    "    print(enhanced_rank.show())\n",
    "    number_of_iterations -= 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6237de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
